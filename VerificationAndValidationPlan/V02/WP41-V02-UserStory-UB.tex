%\subsection{System Integration  Testing (Uni Bremen/DLR)}

This section describes the verification plan of Uni Bremen. It
concerns the test generation for part of the on board unit as
specified in the subset -026. he main goal are :

\begin{enumerate}
\item Create a test model in SysML. From the model evaluation
  activities, the management of the radio communication is already
  available. To cover different aspect of the specification, the
  ceiling speed monitoring model will be also provided.
\item Generate test cases according to the defined interface given by
  DLR. (RT-Tester) 
\item Provide simulation environment for the
  track-to-train simulation (including braking curves/speed
  profiles)\footnote{ OpenETCS system testing for the EVC on-board
    computer requires test execution in real physical time and also
    track layout with realistic speed profiles.  We also want to
    contribute to the track and Speed Simulation by automatically
    generates ``relevant'' layout for OpenETCS.}  along routes used
  for testing
\item Study the automatic generation of these track layouts and speed
  simulations; if feasible, implement a generator and integrated it in
  the DLR laboratory environment
\item Set up a test environments for
  \begin{itemize}  
  \item Hardware-in-the-loop Testing within DLR laboratory.
  \item Software-in-loop testing with code provided by SCADE (Siemens)
  \end{itemize}
\end{enumerate}


\paragraph{Track simulation}
OpenETCS system testing for the EVC on-board computer requires test
execution in real physical time and also track layout with realistic
speed profiles.  We also want to contribute to the track and Speed
Simulation by automatically generates ``relevant'' layout for
OpenETCS.



\paragraph{Test cases generation}
We also plan different activities to ensure the pertinence of our test cases.
\begin{enumerate}
\item Check the test model (SysML) : RTT-BMC or other model checkers
\item Add relevant LTL properties if needed
\item Test case analysis by 
  \begin{itemize}
    \item Structural coverage
    \item Requirement coverage
    \item Mutation coverage 
    \item Data coverage
  \end{itemize}
\end{enumerate}

\paragraph{Test cases analysis -- comparison to Subset 76}
\begin{enumerate}
\item Provide techniques and Howto describing how test cases from
  Subset 76 can be executed in the RT-Tester environment, either as SW
  integration test or as HiL test in the DLR simulation environment
\item Create new set of test cases for the ceiling speed monitoring
  (As far as we know,they do not yet exist in Subset 76)
\item Compare new test cases created by RT-Tester to new test cases
  for ceiling speed monitoring provided by ERTMS standardization
  group, as soon as available; suggest improvements for the Subset 76
  test cases. 
 \end{enumerate}



\paragraph{Object of verification}
\nl
The object of verification is the speed and distance monitoring test model\\
(https://github.com/openETCS/validation/tree/master/VnVUserStories/VnVUserStoryUniBremen/05-Work/SpeedAndDistanceMonitoring)
and represents the chap 13.10.3 of the subset 026.



\paragraph{Available specification}

The specification is the subset 026 chap 3.13.10.1-3, 3.13.10.5-6.
It describes the ceilingand the target speed monitoring of the
train. It specifies when the braking commands should apply depending
on the speed and the position of the train.

\paragraph{Methods and Means}

Model based testing with RT-tester (see section \ref{sec:RTTester}) is used for the tests generation
from a test model design with Papyrus.



\paragraph{Results to be achieved}

The main goal is to obtain automatically generated test that cover
part of the subset 026 for the speed and distance monitoring that can
be then played by the DLR laboratory.
Furthermore, the tests should ensure some coverage criteria, and be
realistic enough to be sound and usable.

In order to have strong and sound test we need to constraints the test
generation. We can see two different approaches. One is to model some physical effect
such as realistic deceleration and acceleration embedded in the test
model.
The second approach consists of adding track layout information to the
model that will generate tests for a given track layout.


\paragraph{Timeline}


\begin{tabular}{lp{5cm}}
December 2014 & Create and improve  the Speed and distance monitoring test model\\
March 2014 &  Generate test conforms to the DLR specification\\
August 2014 & Study how to model stronger environment \\
September 2014 & Study how to generate test for a given track (or partial track) layout\\
September 2014 &  Implement the stronger environment for better test generation\\
November 2014 &  Implement test generation for a given track layout\\
January 2014&  Compare the generated tests with the different environment
  strategies.\\
 February 2015 & Define Test representation\\
 March 2015 & Represent Subset 076 to be compared with the
  generated tests\\
April 2015 & Write Reports \\
\end{tabular}

\paragraph{Maturity Classification}
The RT-tester tool may be divided in the following parts:
\begin{itemize}
\item RT-tester Core: Test Generation, test execution and real-time
  test evaluation.
\item RT-tester SCADE : SCADE interfaces for test execution and test
  simulation of generated C code from SCADE.
\item RT-tester OpenETCS: The new developed parts like the DLR
  laboratory adapter, the test environment parser, the eclipse
  front-end plugin.
\end{itemize}
The tools applied have the following TRLs (Technology Readiness
Levels):

\begin{description}
\item[RT-tester Core:] TRL~9. The tool is in use in different
  projects in industrial context such as Airbus  and
  Siemens. Moreover, the Core have been certified for  ISO 26262 ad RTCA
DO178C.
\item[RT-tester SCADE:] TRL~9. The tool is in use at Siemens.
\item[RT-tester OpenETCS:] TRL~6. The tool is in use within
  openETCS project, but it is still in the prototype phase.
\end{description}

%% \bgcmmnt{Technology readiness level of the tools in analogy to the definitions
%% from
%% \texttt{http://ec.europa.eu/research/participants/data/ref/h2020/
%% wp/2014\_2015/annexes/h2020-wp1415-annex-g-trl\_en.pdf}:

%% \begin{description}
%% \item[TRL 1] basic principles observed
%% \item[TRL 2] technology concept formulated
%% \item[TRL 3] experimental proof of concept
%% \item[TRL 4] technology validated in lab
%% \item[TRL 5] technology validated in relevant environment (industrially relevant
%% environment in the case of key enabling technologies)
%% \item[TRL 6] technology demonstrated in relevant environment (industrially relevant
%% environment in the case of key enabling technologies)
%% \item[TRL 7] system prototype demonstration in operational environment
%% \item[TRL 8] system complete and qualified
%% \item[TRL 9] actual system proven in operational environment (competitive
%% manufacturing in the case of key enabling technologies; or in space)
%% \end{description}
%% These categories are formulated for ``real'' systems, not verification
%% tools, so some interpretation of the definitions is needed. For us,
%% the levels 3 to 6 seem the most probable. SCADE with its simulation
%% capabilities would be an example of a system of higher TRL which could
%% be used in verification. RT Tester (the plugin together with the
%% server installed components) might perhaps be classified as 5 (DLR
%% guess): It has been used like it would be applied in a real
%% development, but not extensively (not demonstrated, just
%% validated. This could be different at the end of the project.).}

%% The activity shall comply in the following way to the requirements of
%% a SIL~4 development.  \tbi{Compliance description} 

%% \bgcmmnt{According to the role the activity would have in a
%%   development process. Tools must be qualified, depending on their
%%   usage (e.g., error detection by supplementing activities). If an
%%   activity is not intended to perform some verification completely,
%%   state what would be needed for being able to use its result. Qualify
%%   your statement if you are not sure about your judgment: e.g., guess,
%%   tentative, informed estimation, or similar.}

